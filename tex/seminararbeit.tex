% !TeX root = ./seminararbeit.tex
%% Preambel
\documentclass[conference,compsoc,final,a4paper]{IEEEtran}
\usepackage[utf8]{inputenx}

%% Bitte legen Sie hier den Titel und den Autor der Arbeit fest
\newcommand{\autoren}[0]{Mundhenke, Moritz}
\newcommand{\dokumententitel}[0]{Spectre and Cloud : An evaluation of threats in shared computation environments }

\input{preambel} % Weitere Einstellungen aus einer anderen Datei lesen

\begin{document}

% Titel des Dokuments
\title{\dokumententitel}

% Namen der Autoren
\author{
  \IEEEauthorblockN{\autoren}
  \IEEEauthorblockA{
    Hochschule Mannheim\\
    Fakultät für Informatik\\
    Paul-Wittsack-Str. 10,
    68163 Mannheim
    }
}

% Titel erzeugen
\maketitle
\thispagestyle{plain}
\pagestyle{plain}

% Eigentliches Dokument beginnt hier
% ----------------------------------------------------------------------------------------------------------

% Kurze Zusammenfassung des Dokuments
\begin{abstract}
\end{abstract}

% Inhaltsverzeichnis erzeugen
\tableofcontents

% Abschnitte mit \section, Unterabschnitte mit \subsection und
% Unterunterabschnitte mit \subsubsection
% -------------------------------------------------------
\section{Einleitung}

% -------------------------------------------------------
\section{Modern computation hardware and infrastructure}
\subsection{Memory management}
* Caches
\subsection{Processor pipelines and speculative execution}
Since the turn of the millennium, clock speeds of high performance CPU's have stagnated because the increased energy consumption and resulting heat generation got
too high. \cite{fog2012microarchitecture} Multi-core architectures became common however even today many, if not most,
workloads rely heavily on single thread performance. Therefore, to increase the speed of single thread execution, without increasing the clock speed,
more instructions have to be executed in a single cycle. To achieve this goal many techniques like instruction splitting, fusion,
and simultaneous instruction execution are used. \cite{fog2012microarchitecture} These optimizations require more complex processing of the instruction stream which
is handled by the processors instruction pipeline. This has resulted in higher pipeline memory requirements as well as a longer pipelines in terms of clock cycles
required for an instruction to complete execution. However, since programs use conditional branches and loops these long pipeline can become invalid because the CPU
cannot know the destination of a conditional jump without first evaluating the condition. This results in a pipeline flush that wastes valuable execution time while
the pipeline is refilled. To mitigate the impact of this issue the processor can store previous outcomes of branches and use this to predict future executions of the
branch. With branch prediction only a miss-prediction will result in a pipeline flush. The CPU runs the instruction of the predicted branch and either commits
the results if the prediction was correct or discards them if was not.
This process is called speculative execution. \cite{kocher2018spectre}
\subsection{Virtual and shared memory}

\subsection{Docker}
\subsubsection*{Containerization concept}
Docker allows isolation of processes in containers. These containers hide other processes running on the host and provide the process with its own virtual filesystem
and network. This means containers only share the hosts kernel which stands in contrast with classical VMs which have to run a separate OS for
each virtual machine. \cite{bernstein2014containers}\\
To create a container an image is used. The image contains all required files and serves as a \enquote{blueprint} for the container. \cite{bernstein2014containers}
Due to the lightweight nature of containers it is possible and best practice to isolate every application in its own container. \cite{dockerBestPractices} For example a
classic PHP and MySQL application, also called LAMP stack (Linux, Apache, MySQL and PHP), would use a MySQL and an Apache container. This has multiple benefits:
Developers can build and test container images on their own machine which will behave identical when run on a production server. Docker also allows easy horizontal
scaling of applications. The LAMP stack mentioned above could be extended by creating an additional Apache container and an nginx container
to load balance between the two Apache servers.
\subsubsection*{File-system layers}
To reduce redundancy docker images are divided into layers. \cite{dockerBestPractices} For example an Apache PHP application would consist of 3
major layers. The first contains a minimal debian image providing basic libraries and tools. The second layer contains Apache and its dependencies. The final
layer would then have a copy of the applications PHP source files. \\
When a container is started from this image, the layers are stacked on top of each other
using a union filesystem like OverlayFS\cite{overlayfs}. Whenever the application attempts to read a file, the kernel checks each layer from top to bottom
returning the first result. This allows overriding of files on lower layers. \\
Because of this multiple different PHP images can share the first two layers and a MySQL image
sharing the base Debian image. Docker also adds a final non-persistent layer to the container which the application running inside uses to write files,
which is discarded when the container is shutdown.
\subsection{Cloud}

% -------------------------------------------------------
\section{Spectre}
\subsection{Side-channels}
Computer programs can, on an abstract level, be described with the \ac{IPO} model. An input will produce an output defined by the algorithms
of the program. This output is deterministic, meaning input \lstinline|a| will always result in output \lstinline|b|. \\
However, in real life systems, processes can produce additional outputs which are not intended by its programmer. For example a program which calculates the
factorial of a number takes longer proportional to the input number. An attacker could therefore, infer the input number from the execution time without knowing the
result. More complex timing-attacks have been used to extract private keys or other secrets
of various cryptographic algorithms. \cite{bernstein2005cache}\cite{kocher1996timing}
Similarly even a systems power consumption can be used as a side-channel to retrieve secret data. \cite{kocher1999differential} \\
While these two side-channels can add unintended output to a process they are within the programmers control. Execution time can be increased arbitrarily through
idling or sleeping and the system's power consumption can be increased by running pointless code. Other side-channels however, are completely outside of the
control of the programmer. For example a program has very limited or no direct control over the systems cache state or which \ac{ALU} will compute a calculation.
\subsection{Exploiting speculative execution}
To execute a spectre exploit the attacker first has to find a vulnerable instruction sequence in the victim program. The sequence will leak secret data into the chosen
side-channel during speculative execution. Therefore, spectre-style attacks can be differentiated from each other by the how speculative execution is achieved
and what side-channel is used. \cite{kocher2018spectre} \\
The example of Variant 1 of the original spectre attack uses conditional branches to achieve speculative
execution and leaks data through the processors cache state. The conditional branch is an array bounds check \lstinline|if (x < array1_size)|. The branch prediction
can be miss-trained by repeatedly calling the victim function with an in-bounds \lstinline|x| causing it to predict the branch as true in the future. Then the
attacker flushes \lstinline|array1_size| from the processors cache and calls the victim function again. This causes the branch to be execute speculatively
until \lstinline|array1_size| is retrieved from memory. \\
To leak the victims secret the attacker chooses an \lstinline|x| that is out of bounds. The victim
now reads from \lstinline|array1| using the malicious, out-of-bounds address. To successfully execute the attack sequence the victim also has to use the result to
access a second array. This causes the processor to load a memory address into the cache which is based of the previous out-of-bounds access of \lstinline|array[x]|.
The attacker can now time their own access of the possible memory addresses, revealing which address can be read fastest and was therefore retrieved by the victims
speculative execution, revealing the (secret) value of \lstinline|array[x]|.
% -------------------------------------------------------
\section{Spectre in shared cloud infrastructure}

\subsection{Shared hypervisor}
\ac{IaaS} providers give their customers, here referred to as tenants, the ability to rent virtual machines. The tenant has full access
to this VM (root access). Since most applications do not require the full capabilities of the physical server, multiple VMs are run on a hypervisor such as VMware
ESXi or Linux's KVM. \\
This results in the sharing of physical resources like RAM and CPU cores between tenants. This isolation is hardware enforced
and hypervisor exploits are quite rare (only 5 ESXi vulnerabilities in 2018 with a score $\ge$ 5) \cite{esxiVulnerabilities}. However, since speculative execution can
circumvent hardware enforced checks, some Spectre vulnerabilities allowed an attacker to read the memory of another tenants VMs and the hypervisor
itself \cite{vmwareSpectre, vmwareSpectreNG}. While the currently known Spectre attacks have been mitigated by hypervisor patches, speculative execution exploits
found in the future could still allow cross VM attacks in the cloud. \\
In a public cloud an adversary is faced with another hurdle besides VM isolation. Because the \ac{IaaS} provider allocates resources for the tenants based on the their
requirements through a closed-source algorithm, an attacker can not directly force co-residency (share a hypervisor) with the victim. \\
\textcite{Ristenpart:2009:HYG:1653662.1653687} demonstrated various networking based techniques to achieve co-residency in the early (2009) \ac{AWS} cloud and while Amazon
has improved security in this regard, other co-residency detection mechanisms have been found \cite{inci2015seriously}. This newer method uses information leaks
on the processor level, specifically through the last level cache shared between all CPU cores.
\subsection{Shared Docker host}
Running docker containers in the cloud can have benefits for both the customer and the cloud provider. The customer does not have to worry about maintenance
of the underlying operating system and can more easily scale their application. The cloud provider can, in theory, increase utilization of their hardware
because of the reduced overhead. \\
However, leveraging these benefits requires faith in the process isolation provided by Docker and the Linux kernel. Because of this the Azure and \ac{AWS} public
cloud isolate containers using hypervisor technology, only sharing kernels between containers of the same user defined application group
\cite{fargateIsolation, azureIsolation}. Due to this the
potential price advantage is lost. The smallest possible \ac{AWS} Fargate task configuration (0.25 vCPU and 0.5 GB RAM) costs 0.01234 USD per hour\cite{fargatePricing}
while the EC2 t3.micro VM (2 vCPU and 1 GB RAM) only costs 0.0104 USD per hour \cite{ec2Pricing}. \\
Other \ac{PaaS} providers like
Heroku\cite{herokuIsolation}, OpenShift\cite{openshiftIsolation} and the defunct DotCloud however, do not use the additional isolation provided
by hypervisor virtualization\cite{zhang2014cross}. \\
These providers do refer to various \enquote{Docker hardening} techniques, however, specifics like the usage of
shared libraries between containers are not mentioned, which can provide attack surface area for Spectre exploits. \cite{retpolineTurner}
\subsection{\acs{FaaS} -- Function as a Service}
\acs{FaaS} further abstracts service infrastructure. Conceptually a developer writes a function, uploads it to the \acs{FaaS} service and connects events like HTTP requests or
database events as an input source. \\
When an event occurs the function is called with the event's parameters and, in the case of an HTTP request, builds and
returns a API response. The benefits are automatic scaling and a payment model where the customer only pays for the functions execution time. \cite{lambdaFeatures}\\
In reality a \enquote{function} is a package of code, configuration and module/library files. Therefore, even if the service for example only allows Node.JS execution
this cannot be considered a security feature as a node module can contain native, compiled binary files. \cite{lambdaFaq} \\
Due to the high abstraction level, internal implementation details are sparsely documented. \ac{AWS} Lambda notes that Lambda functions are isolated using EC2 techniques, i.e.
hypervisor isolation\cite{lambdaFaq}. \ac{GCF} in contrast only states that functions are run in
\enquote{its own isolated secure execution context}\cite{cloudFunc}. \textcite{wang2018peeking} further investigates \acs{FaaS} implementations. \\
If a \acs{FaaS} would only use docker to isolate functions of different customers, the risk of a speculative attack would be higher compared to a Docker \ac{PaaS} provider. Since function are based on small number of available runtime environments (e.g.\ \ac{GCF}: Go, Python and Node.js 6,8,10) \cite{cloudFunc} an attacker has implicit knowledge
about the victims shared library and executable files. \\
Therefore, an attacker could not only attempt co-residency to gain access to a specific target's secrets, but instead mount a broader attack acquiring data from random
other tenants. Similar to spam phishing emails the goal would not be one large \enquote{heist} but instead gaining value from many smaller thefts.
% -------------------------------------------------------
\section{Prevention and detection}
\subsection{In-memory encryption}
\subsection{Heuristic detection}

% --------------------------------------------------------------------
\section*{Abkürzungen}
\addcontentsline{toc}{section}{Abkürzungen}

% Die längste Abkürzung wird in die eckigen Klammern
% bei \begin{acronym} geschrieben, um einen hässlichen
% Umbruch zu verhindern
% Sie müssen die Abkürzungen selbst alphabetisch sortieren!
\begin{acronym}[IEEE]
\acro{IaaS}{Infrastructure as a Service}
\acro{AWS}{Amazon Web Services}
\acro{FaaS}{Function as a Service}
\acro{GCF}{Google Cloud Functions}
\acro{ALU}{arithmetic logic unit}
\acro{IPO}{input-process-output}
\acro{PaaS}{Platform as a Service}
\end{acronym}

% Literaturverzeichnis
\addcontentsline{toc}{section}{Literatur}
\printbibliography

\end{document}
